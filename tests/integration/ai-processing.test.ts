import request from 'supertest';
import { app } from '../../src/app';
import { VertexAIService } from '../../src/services/vertexai.service';
import { QueueService } from '../../src/services/queue.service';
import { QueueController } from '../../src/controllers/queue.controller';
import { AIResponse } from '../../src/models/vertexai.model';
import { TaskCreationResult } from '../../src/models/queue.model';\n\n// Mock external services for integration testing\njest.mock('../../src/services/vertexai.service');\njest.mock('../../src/services/queue.service');\njest.mock('../../src/services/monitoring.service', () => ({\n  monitoringService: {\n    logTokenUsage: jest.fn(),\n    logVertexAIPerformance: jest.fn(),\n    logSlackWebhookPerformance: jest.fn(),\n  },\n}));\njest.mock('../../src/utils/logger', () => ({\n  logger: {\n    logUserAction: jest.fn(),\n    info: jest.fn(),\n    error: jest.fn(),\n    warn: jest.fn(),\n    startTimer: jest.fn(() => jest.fn()),\n  },\n}));\n\n// Mock fetch for Slack webhook calls\nglobal.fetch = jest.fn();\n\ndescribe('AI Processing Integration Tests', () => {\n  let mockVertexAIService: jest.Mocked<VertexAIService>;\n  let mockQueueService: jest.Mocked<QueueService>;\n\n  const validAITaskRequest = {\n    requestId: 'req-integration-test-123',\n    prompt: 'Analyze this sales data and provide insights',\n    data: 'Q1 Sales: $125K, Q2 Sales: $180K, Q3 Sales: $165K, Q4 Sales: $220K',\n    userId: 'U987654321',\n    channelId: 'C987654321',\n    workspaceId: 'T987654321',\n    responseUrl: 'https://hooks.slack.com/commands/integration/test',\n    priority: 'NORMAL',\n    createdAt: '2024-01-15T14:30:00.000Z',\n    metadata: {\n      userName: 'analyst',\n      teamName: 'Sales Analytics',\n      originalCommand: '/ai \"Analyze sales data\" \"Q1-Q4 data\"',\n      retryCount: 0,\n    },\n  };\n\n  const mockAIResponse: AIResponse = {\n    content: 'Based on the sales data analysis:\\n\\nâ€¢ Q1 to Q2: 44% growth\\nâ€¢ Q2 to Q3: -8% decline\\nâ€¢ Q3 to Q4: 33% growth\\nâ€¢ Overall trend: Strong performance with Q4 being the best quarter',\n    tokenUsage: {\n      inputTokens: 85,\n      outputTokens: 65,\n      totalTokens: 150,\n    },\n    processingTimeMs: 2100,\n    requestId: 'req-integration-test-123',\n    metadata: {\n      modelId: 'gemini-2.5-flash-001',\n      finishReason: 'STOP',\n      safetyRatings: [],\n      generatedAt: new Date('2024-01-15T14:30:02.100Z'),\n    },\n  };\n\n  beforeAll(() => {\n    // Set test environment variables\n    process.env.NODE_ENV = 'test';\n    process.env.GCP_PROJECT_ID = 'writerly-01';\n    process.env.VERTEX_AI_MODEL_ID = 'gemini-2.5-flash-001';\n    process.env.ENCRYPTION_KEY = 'test-key-32-bytes-long-for-test-';\n    process.env.SLACK_SIGNING_SECRET = 'test-slack-signing-secret';\n  });\n\n  beforeEach(() => {\n    jest.clearAllMocks();\n\n    // Mock VertexAI Service\n    mockVertexAIService = {\n      generateResponse: jest.fn(),\n      getConfig: jest.fn(),\n      disconnect: jest.fn(),\n    } as any;\n\n    (VertexAIService as jest.MockedClass<typeof VertexAIService>).mockImplementation(\n      () => mockVertexAIService\n    );\n\n    // Mock Queue Service\n    mockQueueService = {\n      enqueueAIRequest: jest.fn(),\n      getQueueStats: jest.fn(),\n      disconnect: jest.fn(),\n      getConfig: jest.fn(),\n      getQueuePath: jest.fn(),\n    } as any;\n\n    (QueueService as jest.MockedClass<typeof QueueService>).mockImplementation(\n      () => mockQueueService\n    );\n\n    // Mock successful Slack webhook by default\n    (global.fetch as jest.Mock).mockResolvedValue({\n      ok: true,\n      status: 200,\n      statusText: 'OK',\n      json: jest.fn().mockResolvedValue({ ok: true }),\n    });\n  });\n\n  describe('Full AI Processing Pipeline Integration', () => {\n    it('should complete full AI processing flow: Queue â†’ VertexAI â†’ Slack', async () => {\n      // Arrange: Mock successful AI generation\n      mockVertexAIService.generateResponse.mockResolvedValue(mockAIResponse);\n\n      // Act: Process AI task through queue controller endpoint\n      const response = await request(app)\n        .post('/queue/process')\n        .send(validAITaskRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      // Assert: Verify successful processing\n      expect(response.status).toBe(200);\n      expect(response.body).toMatchObject({\n        success: true,\n        requestId: 'req-integration-test-123',\n        processingTimeMs: expect.any(Number),\n        tokenUsage: {\n          inputTokens: 85,\n          outputTokens: 65,\n          totalTokens: 150,\n        },\n        priority: 'NORMAL',\n      });\n\n      // Verify VertexAI service was called with correct parameters\n      expect(mockVertexAIService.generateResponse).toHaveBeenCalledWith({\n        prompt: 'Analyze this sales data and provide insights',\n        data: 'Q1 Sales: $125K, Q2 Sales: $180K, Q3 Sales: $165K, Q4 Sales: $220K',\n        requestId: 'req-integration-test-123',\n        userId: 'U987654321',\n        contextMetadata: {\n          channelId: 'C987654321',\n          workspaceId: 'T987654321',\n          userName: 'analyst',\n          timestamp: new Date('2024-01-15T14:30:00.000Z'),\n        },\n      });\n\n      // Verify Slack webhook was called with formatted message\n      expect(fetch).toHaveBeenCalledWith(\n        'https://hooks.slack.com/commands/integration/test',\n        {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n          },\n          body: expect.stringContaining('Based on the sales data analysis'),\n          signal: expect.any(AbortSignal),\n        }\n      );\n\n      // Verify Slack message format\n      const fetchCall = (global.fetch as jest.Mock).mock.calls[0];\n      const slackMessage = JSON.parse(fetchCall[1].body);\n      expect(slackMessage).toMatchObject({\n        response_type: 'in_channel',\n        text: expect.stringContaining('AI ì‘ë‹µ'),\n        blocks: expect.arrayContaining([\n          expect.objectContaining({\n            type: 'section',\n            text: expect.objectContaining({\n              text: expect.stringContaining('Based on the sales data analysis'),\n            }),\n          }),\n          expect.objectContaining({\n            type: 'context',\n            elements: expect.arrayContaining([\n              expect.objectContaining({\n                text: expect.stringMatching(/ìƒì„± ì‹œê°„: .* \\| ìš”ì²­ ID: req-inte/),\n              }),\n            ]),\n          }),\n        ]),\n      });\n    });\n\n    it('should handle end-to-end processing with only prompt (no data)', async () => {\n      const promptOnlyRequest = {\n        ...validAITaskRequest,\n        data: undefined,\n        prompt: 'What are the key factors for successful product launches?',\n      };\n\n      const promptOnlyResponse = {\n        ...mockAIResponse,\n        content: 'Key factors for successful product launches: 1) Market research, 2) Clear value proposition, 3) Strong marketing strategy, 4) Quality product, 5) Customer feedback integration',\n        tokenUsage: {\n          inputTokens: 45,\n          outputTokens: 55,\n          totalTokens: 100,\n        },\n      };\n\n      mockVertexAIService.generateResponse.mockResolvedValue(promptOnlyResponse);\n\n      const response = await request(app)\n        .post('/queue/process')\n        .send(promptOnlyRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      expect(response.status).toBe(200);\n      expect(response.body.success).toBe(true);\n\n      // Verify AI was called with undefined data\n      expect(mockVertexAIService.generateResponse).toHaveBeenCalledWith(\n        expect.objectContaining({\n          data: undefined,\n          prompt: 'What are the key factors for successful product launches?',\n        })\n      );\n\n      // Verify Slack message contains the response\n      expect(fetch).toHaveBeenCalledWith(\n        expect.any(String),\n        expect.objectContaining({\n          body: expect.stringContaining('Key factors for successful product launches'),\n        })\n      );\n    });\n\n    it('should process high-priority tasks correctly', async () => {\n      const highPriorityRequest = {\n        ...validAITaskRequest,\n        priority: 'HIGH',\n        prompt: 'URGENT: Analyze critical system metrics',\n      };\n\n      mockVertexAIService.generateResponse.mockResolvedValue({\n        ...mockAIResponse,\n        content: 'CRITICAL ANALYSIS: System shows 95% CPU usage, memory at 88%, immediate optimization required.',\n        processingTimeMs: 800, // Faster processing for high priority\n      });\n\n      const response = await request(app)\n        .post('/queue/process')\n        .send(highPriorityRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      expect(response.status).toBe(200);\n      expect(response.body.priority).toBe('HIGH');\n      expect(response.body.success).toBe(true);\n    });\n\n    it('should track comprehensive monitoring metrics', async () => {\n      const { monitoringService } = require('../../src/services/monitoring.service');\n      mockVertexAIService.generateResponse.mockResolvedValue(mockAIResponse);\n\n      const response = await request(app)\n        .post('/queue/process')\n        .send(validAITaskRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      expect(response.status).toBe(200);\n\n      // Verify token usage monitoring\n      expect(monitoringService.logTokenUsage).toHaveBeenCalledWith(\n        'req-integration-test-123',\n        'U987654321',\n        'T987654321',\n        {\n          inputTokens: 85,\n          outputTokens: 65,\n          totalTokens: 150,\n          model: 'gemini-2.5-flash-001',\n          timestamp: expect.any(Date),\n          cost: expect.any(Number),\n        }\n      );\n\n      // Verify VertexAI performance monitoring\n      expect(monitoringService.logVertexAIPerformance).toHaveBeenCalledWith(\n        'req-integration-test-123',\n        'gemini-2.5-flash-001',\n        validAITaskRequest.prompt.length,\n        mockAIResponse.content.length,\n        mockAIResponse.tokenUsage,\n        expect.any(Number),\n        true\n      );\n\n      // Verify Slack webhook performance monitoring\n      expect(monitoringService.logSlackWebhookPerformance).toHaveBeenCalledWith(\n        'req-integration-test-123',\n        'https://hooks.slack.com/commands/integration/test',\n        expect.any(Number),\n        200,\n        true\n      );\n    });\n  });\n\n  describe('Error Handling and Recovery', () => {\n    it('should handle VertexAI service failures gracefully', async () => {\n      // Arrange: Mock AI service failure\n      const aiError = new Error('VertexAI service temporarily unavailable');\n      mockVertexAIService.generateResponse.mockRejectedValue(aiError);\n\n      // Act: Process task\n      const response = await request(app)\n        .post('/queue/process')\n        .send(validAITaskRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      // Assert: Should return error response\n      expect(response.status).toBeGreaterThanOrEqual(400);\n      expect(response.body).toMatchObject({\n        error: expect.any(String),\n        requestId: 'req-integration-test-123',\n      });\n\n      // Verify monitoring was called for failed AI processing\n      const { monitoringService } = require('../../src/services/monitoring.service');\n      expect(monitoringService.logVertexAIPerformance).toHaveBeenCalledWith(\n        'req-integration-test-123',\n        'unknown',\n        expect.any(Number),\n        0,\n        expect.objectContaining({ inputTokens: 0, outputTokens: 0, totalTokens: 0 }),\n        expect.any(Number),\n        false\n      );\n    });\n\n    it('should handle Slack webhook failures while preserving AI response', async () => {\n      // Arrange: Mock successful AI but failed Slack webhook\n      mockVertexAIService.generateResponse.mockResolvedValue(mockAIResponse);\n      (global.fetch as jest.Mock).mockRejectedValue(new Error('Slack webhook timeout'));\n\n      // Act: Process task\n      const response = await request(app)\n        .post('/queue/process')\n        .send(validAITaskRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      // Assert: Should return partial success\n      expect(response.status).toBe(200);\n      expect(response.body).toMatchObject({\n        success: true,\n        requestId: 'req-integration-test-123',\n        tokenUsage: mockAIResponse.tokenUsage,\n        warning: expect.stringContaining('Slack ì „ì†¡ì— ì‹¤íŒ¨'),\n        aiResponse: {\n          contentLength: mockAIResponse.content.length,\n          modelUsed: 'gemini-2.5-flash-001',\n        },\n      });\n\n      // Verify Slack webhook failure was monitored\n      const { monitoringService } = require('../../src/services/monitoring.service');\n      expect(monitoringService.logSlackWebhookPerformance).toHaveBeenCalledWith(\n        'req-integration-test-123',\n        'https://hooks.slack.com/commands/integration/test',\n        expect.any(Number),\n        500,\n        false\n      );\n    });\n\n    it('should validate request data comprehensively', async () => {\n      const invalidRequests = [\n        {\n          // Missing requestId\n          prompt: 'Test prompt',\n          userId: 'U123456',\n          responseUrl: 'https://hooks.slack.com/test',\n          workspaceId: 'T123456',\n          createdAt: new Date().toISOString(),\n        },\n        {\n          // Empty prompt\n          requestId: 'req-test',\n          prompt: '',\n          userId: 'U123456',\n          responseUrl: 'https://hooks.slack.com/test',\n          workspaceId: 'T123456',\n          createdAt: new Date().toISOString(),\n        },\n        {\n          // Prompt too long\n          requestId: 'req-test',\n          prompt: 'a'.repeat(10001),\n          userId: 'U123456',\n          responseUrl: 'https://hooks.slack.com/test',\n          workspaceId: 'T123456',\n          createdAt: new Date().toISOString(),\n        },\n      ];\n\n      for (const invalidRequest of invalidRequests) {\n        const response = await request(app)\n          .post('/queue/process')\n          .send(invalidRequest)\n          .set('Content-Type', 'application/json')\n          .set('Authorization', 'Bearer mock-oidc-token');\n\n        expect(response.status).toBeGreaterThanOrEqual(400);\n        expect(response.body).toHaveProperty('error');\n        expect(mockVertexAIService.generateResponse).not.toHaveBeenCalled();\n        \n        jest.clearAllMocks();\n      }\n    });\n\n    it('should implement retry logic for recoverable failures', async () => {\n      // Arrange: Mock initial failure then success\n      const retryableError = new Error('Temporary service unavailable');\n      const successfulRetry = mockAIResponse;\n\n      mockVertexAIService.generateResponse\n        .mockRejectedValueOnce(retryableError)\n        .mockResolvedValueOnce(successfulRetry);\n\n      // Act: Process task\n      const response = await request(app)\n        .post('/queue/process')\n        .send(validAITaskRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      // Assert: Should succeed after retry\n      expect(response.status).toBe(200);\n      expect(response.body.success).toBe(true);\n      \n      // Verify retry was attempted\n      expect(mockVertexAIService.generateResponse).toHaveBeenCalledTimes(2);\n    });\n  });\n\n  describe('Performance and Scalability', () => {\n    it('should handle large data payloads efficiently', async () => {\n      const largeDataRequest = {\n        ...validAITaskRequest,\n        prompt: 'Analyze this comprehensive dataset',\n        data: 'Large dataset: ' + JSON.stringify(Array.from({ length: 1000 }, (_, i) => ({\n          id: i,\n          value: Math.random() * 1000,\n          category: `Category ${i % 10}`,\n          timestamp: new Date(Date.now() - i * 86400000).toISOString(),\n        }))),\n      };\n\n      const largeDataResponse = {\n        ...mockAIResponse,\n        content: 'Comprehensive analysis of 1000 data points reveals significant patterns across 10 categories with strong temporal correlations.',\n        tokenUsage: {\n          inputTokens: 2500,\n          outputTokens: 150,\n          totalTokens: 2650,\n        },\n        processingTimeMs: 5200,\n      };\n\n      mockVertexAIService.generateResponse.mockResolvedValue(largeDataResponse);\n\n      const startTime = Date.now();\n      const response = await request(app)\n        .post('/queue/process')\n        .send(largeDataRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n      const endTime = Date.now();\n\n      expect(response.status).toBe(200);\n      expect(response.body.tokenUsage.totalTokens).toBe(2650);\n      expect(endTime - startTime).toBeLessThan(10000); // Should complete within 10 seconds\n    });\n\n    it('should handle concurrent requests properly', async () => {\n      mockVertexAIService.generateResponse.mockResolvedValue(mockAIResponse);\n\n      // Create multiple concurrent requests\n      const concurrentRequests = Array.from({ length: 5 }, (_, i) => {\n        const request = {\n          ...validAITaskRequest,\n          requestId: `req-concurrent-${i}`,\n          prompt: `Concurrent request ${i}: Analyze data`,\n          userId: `U${i}`,\n        };\n\n        return request(app)\n          .post('/queue/process')\n          .send(request)\n          .set('Content-Type', 'application/json')\n          .set('Authorization', 'Bearer mock-oidc-token');\n      });\n\n      // Execute all requests concurrently\n      const responses = await Promise.all(concurrentRequests);\n\n      // Verify all requests succeeded\n      responses.forEach((response, index) => {\n        expect(response.status).toBe(200);\n        expect(response.body.success).toBe(true);\n        expect(response.body.requestId).toBe(`req-concurrent-${index}`);\n      });\n\n      // Verify all AI service calls were made\n      expect(mockVertexAIService.generateResponse).toHaveBeenCalledTimes(5);\n    });\n\n    it('should measure and report accurate processing times', async () => {\n      // Mock a realistic processing delay\n      mockVertexAIService.generateResponse.mockImplementation(\n        () => new Promise((resolve) => {\n          setTimeout(() => resolve(mockAIResponse), 500); // 500ms delay\n        })\n      );\n\n      const startTime = Date.now();\n      const response = await request(app)\n        .post('/queue/process')\n        .send(validAITaskRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n      const endTime = Date.now();\n\n      expect(response.status).toBe(200);\n      expect(response.body.processingTimeMs).toBeGreaterThanOrEqual(500);\n      expect(response.body.processingTimeMs).toBeLessThanOrEqual(endTime - startTime + 100);\n    });\n  });\n\n  describe('Security and Validation', () => {\n    it('should handle malformed JSON gracefully', async () => {\n      const response = await request(app)\n        .post('/queue/process')\n        .send('invalid json{')\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      expect(response.status).toBeGreaterThanOrEqual(400);\n      expect(mockVertexAIService.generateResponse).not.toHaveBeenCalled();\n    });\n\n    it('should validate special characters in input safely', async () => {\n      const specialCharRequest = {\n        ...validAITaskRequest,\n        prompt: 'Analyze: <script>alert(\"xss\")</script> & malicious input',\n        data: 'Data with íŠ¹ìˆ˜ë¬¸ìž and Ã©mojis ðŸš€ and quotes \"test\"',\n      };\n\n      const sanitizedResponse = {\n        ...mockAIResponse,\n        content: 'Analysis complete. Input contained special characters which were handled safely.',\n      };\n\n      mockVertexAIService.generateResponse.mockResolvedValue(sanitizedResponse);\n\n      const response = await request(app)\n        .post('/queue/process')\n        .send(specialCharRequest)\n        .set('Content-Type', 'application/json')\n        .set('Authorization', 'Bearer mock-oidc-token');\n\n      expect(response.status).toBe(200);\n      expect(response.body.success).toBe(true);\n\n      // Verify Slack message was sent safely\n      const fetchCall = (global.fetch as jest.Mock).mock.calls[0];\n      const slackMessage = JSON.parse(fetchCall[1].body);\n      expect(slackMessage.text).toContain('Analysis complete');\n    });\n  });\n\n  afterEach(() => {\n    jest.restoreAllMocks();\n  });\n\n  afterAll(() => {\n    // Clean up environment variables\n    delete process.env.NODE_ENV;\n    delete process.env.GCP_PROJECT_ID;\n    delete process.env.VERTEX_AI_MODEL_ID;\n    delete process.env.ENCRYPTION_KEY;\n    delete process.env.SLACK_SIGNING_SECRET;\n  });\n});